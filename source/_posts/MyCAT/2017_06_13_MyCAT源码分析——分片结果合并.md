title: MyCAT 源码解析 —— 分片结果合并
date: 2017-06-13
tags:
categories: MyCAT
permalink: MyCAT/sharding-result-merge

---

# 1. 概述

相信很多同学都看过 MySQL 各种优化的文章，里面 99% 都会提到：单表数据量大了，需要进行分片。拆分之后，业务上必然面临的场景：跨分片的数据合并。今天我们就一起来瞅瞅 MyCAT 是如何实现**分片结果合并**。

跨分片查询大体流程如下：

![flow](http://www.yunai.me/images/MyCAT/2017_06_13/flow.png)

和 [《【单库单表】查询》](http://www.yunai.me/Mycat/single-db-single-table-select/) 不同的两个过程：

* 【2】多分片执行 SQL
* 【4】合并多分片结果

下面，我们逐条来讲解这两个过程。

# 2. 多分片执行 SQL

![execute_sql](http://www.yunai.me/images/MyCAT/2017_06_13/execute_sql.png)

经过 SQL 解析后，计算出需要执行 SQL 的**分片节点**，遍历**分片节点**发送 SQL 进行执行。核心代码：【[MultiNodeQueryHandler.java#execute(...)](https://github.com/YunaiV/Mycat-Server/blob/1.6/src/main/java/io/mycat/backend/mysql/nio/handler/MultiNodeQueryHandler.java)】。

_**SQL 解析** 详细过程，我们另开文章，避免内容过多，影响大家对 **分片结果合并** 流程和逻辑的理解。_

# 3. 合并多分片结果

![handle_response](http://www.yunai.me/images/MyCAT/2017_06_13/handle_response.png)

和 [《【单库单表】查询》](http://www.yunai.me/Mycat/single-db-single-table-select/) 不同，多个**分片节点**都会**分别**响应 _记录头(header)_ 和 _记录行(row)_ 。在开始分析 MyCAT 是怎么合并多分片结果之前，我们先来回想下 SQL 的执行顺序。

```SQL
FROM       // [1] 选择表
WHERE      // [2] 过滤表
GROUP BY   // [3] 分组
SELECT     // [4] 普通字段，max / min / avg / sum / count 等函数，distinct
HAVING     // [5] 再过滤表
ORDER BY   // [6] 排序
LIMIT      // [7] 分页
```

## 3.1 记录头(header)

多个**分片节点**响应时，会响应多次 _记录头(header)_ 。MyCAT 实际在处理时，只处理第一个返回的 _记录头(header)_ 。因此，在使用时要保证表的 Schema 相同。

**分片节点**响应的 _记录头(header)_ 可以直接返回 MySQL Client 吗？答案是不可以。`AVG`函数 是特殊情况，MyCAT 需要将 `AVG` 拆成 `SUM` + `COUNT` 进行计算。举个例子：

```SQL
// [1] MySQL Client => MyCAT ：
SELECT AVG(age) FROM student;

// [2] MyCAT => MySQL Server ：
SELECT SUM(age) AS AVG0SUM, COUNT(age) AS AVG0COUNT FROM student;

// [3] 最终：AVG(age) = SUM(age) AS AVG0SUM / COUNT(age)
```

核心代码：【[MultiNodeQueryHandler.java#fieldEofResponse(...)](https://github.com/YunaiV/Mycat-Server/blob/1.6/src/main/java/io/mycat/backend/mysql/nio/handler/MultiNodeQueryHandler.java)】

## 3.2 记录行(row)

### 3.1 AbstractDataNodeMerge

MyCAT 对分片结果合并通过 `AbstractDataNodeMerge` 子类来完成。

![merge_service](http://www.yunai.me/images/MyCAT/2017_06_13/merge_service.png) 

`AbstractDataNodeMerge` ：

* -packs ：待合并记录行(row)队列。队列尾部插入 `END_FLAG_PACK` 表示队列已结束。
* -running ：合并逻辑是否正在执行中的标记。
* ~onRowMetaData(...) ：根据**记录列信息(ColMeta)**构建对应的排序组件和聚合组件。需要子类进行实现。
* ~onNewRecord(...) ：插入记录行(row) 到 `packs`。
* ~outputMergeResult(...) ：插入 `END_FLAG_PACK` 到 `packs`。
* ~run(...) ：执行**合并**分片结果逻辑，并将合并结果返回给 MySQL Client。需要子类进行实现。

TODO 简单逻辑图

详细代码见：TODO

### 3.2 DataNodeMergeManager

`AbstractDataNodeMerge` 有两种子类实现：

* `DataMergeService` ：基于**堆内内存**合并分片结果。
* `DataNodeMergeManager` ：基于**堆外内存**合并分片结果。

目前官方默认配置使用 `DataNodeMergeManager`。主要有如下优点：

1. 可以使用更大的内存空间。当并发量大或者数据量大时，更大的内存空间意味着更好的性能。
2. 减少 GC 暂停时间。记录行(row)对象小且重用性很低，需要能够进行类似 C / C++ 的自主内存释放。
3. 更快的内存复制和读取速度，对排序和聚合带来很好的提速。

如果对**堆外内存**不太了解，推荐阅读如下文章：

1. [《从0到1起步-跟我进入堆外内存的奇妙世界》](http://www.jianshu.com/p/50be08b54bee)
2. [《堆内内存还是堆外内存？》](http://www.infoq.com/cn/news/2014/12/external-memory-heap-memory)
3. [《JAVA堆外内存》](http://www.cnblogs.com/moonandstar08/p/5107648.html)
4. [《JVM源码分析之堆外内存完全解读》](https://yq.aliyun.com/articles/2948?spm=5176.100239.blogcont62539.11.a3HdFE)

本文主要分析 `DataNodeMergeManager` 实现，`DataMergeService` 可以自己阅读或者等待后续文章（😈**欢迎订阅我的公众号噢**）。

`DataNodeMergeManager` 有三个组件：

* `globalSorter` ：`UnsafeExternalRowSorter` => 实现记录行(row)**合并并排序**逻辑。
* `globalMergeResult` ：`UnsafeExternalRowSorter` => 实现记录行(row)**合并不排序**逻辑。
* `unsafeRowGrouper` ： `UnsafeRowGrouper` => 实现记录行(row)**聚合**逻辑。

`DataNodeMergeManager#run(...)` 逻辑如下：

1. 写入记录行(row)到 `UnsafeRow`。
2. 根据情况插入到 `globalSorter`、

TODO 再考虑下怎么表述

### 3.3 UnsafeRow

### 3.4 UnsafeExternalRowSorter

### 3.5 UnsafeRowGrouper


